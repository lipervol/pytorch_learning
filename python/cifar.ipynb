{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58e93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as op\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7a29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans = torchvision.transforms.Compose([torchvision.transforms.Resize((32,32)),\n",
    "                            torchvision.transforms.ToTensor()])\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./datasets\",train=True,download=True,transform=trans)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./datasets\",train=False,download=True,transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620bd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5333023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,strides=1,residual_path=False):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.strides = strides\n",
    "        self.residual_path = residual_path\n",
    "        \n",
    "        self.c1 = nn.Conv2d(in_channels,out_channels,(3,3),stride=strides,padding=1,bias=False)\n",
    "        self.b1 = nn.BatchNorm2d(out_channels)\n",
    "        self.a1 = nn.ReLU()\n",
    "        \n",
    "        self.c2 = nn.Conv2d(out_channels,out_channels,(3,3),stride=1,padding=1,bias=False)\n",
    "        self.b2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        if self.residual_path:\n",
    "            self.down_c1 = nn.Conv2d(in_channels,out_channels,(1,1),stride=strides,padding=0,bias=False)         \n",
    "            self.down_b1 = nn.BatchNorm2d(out_channels)\n",
    "            \n",
    "        self.a2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        residual = inputs\n",
    "        x = self.c1(inputs)\n",
    "        x = self.b1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.c2(x)\n",
    "        y = self.b2(x)             \n",
    "        if self.residual_path:\n",
    "            residual = self.down_c1(residual)\n",
    "            residual = self.down_b1(residual)  \n",
    "        outputs = self.a2(y+residual)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17eac70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,(3,3),stride=1,padding=1,bias=False)\n",
    "        self.b1 = nn.BatchNorm2d(64)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.r1 = ResnetBlock(64,64,residual_path=False)\n",
    "        self.r2 = ResnetBlock(64,64,residual_path=False)\n",
    "        self.r3 = ResnetBlock(64,128,strides=2,residual_path=True)\n",
    "        self.r4 = ResnetBlock(128,128,residual_path=False)\n",
    "        self.r5 = ResnetBlock(128,256,strides=2,residual_path=True)\n",
    "        self.r6 = ResnetBlock(256,256,residual_path=False) \n",
    "        self.r7 = ResnetBlock(256,512,strides=2,residual_path=True)\n",
    "        self.r8 = ResnetBlock(512,512,residual_path=False)\n",
    "        self.p1 = nn.AdaptiveAvgPool2d(1)\n",
    "        self.f1 = nn.Flatten()\n",
    "        self.l1 = nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        outputs = self.c1(inputs)\n",
    "        outputs = self.b1(outputs)\n",
    "        outputs = self.a1(outputs)\n",
    "        outputs = self.r1(outputs)\n",
    "        outputs = self.r2(outputs)\n",
    "        outputs = self.r3(outputs)\n",
    "        outputs = self.r4(outputs)\n",
    "        outputs = self.r5(outputs)\n",
    "        outputs = self.r6(outputs)\n",
    "        outputs = self.r7(outputs)\n",
    "        outputs = self.r8(outputs)\n",
    "        outputs = self.p1(outputs)\n",
    "        outputs = self.f1(outputs)\n",
    "        outputs = self.l1(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86088ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Load Model...\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./save.pth\"\n",
    "if os.path.exists(save_path):\n",
    "    model = torch.load(save_path)\n",
    "    print(\"[*]Load Model...\")\n",
    "else:\n",
    "    model = ResNet18()\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "loss = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = op.Adam(model.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67be95fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Start Training...\n"
     ]
    }
   ],
   "source": [
    "train_eposchs = 0\n",
    "print(\"[*]Start Training...\")\n",
    "for epochs in range(train_eposchs):\n",
    "    model.train()\n",
    "    for datas in train_loader:\n",
    "        imgs,labels = datas\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        losses = loss(outputs,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    print(\"[*]Eposch:\",epochs+1,\"\\nTrain Loss:\",losses.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        \n",
    "        for datas in test_loader:\n",
    "            imgs,labels = datas\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            outputs = model(imgs)\n",
    "            pred = outputs.argmax(dim = 1)\n",
    "        \n",
    "            correct = torch.eq(pred,labels).float().sum().item()\n",
    "            total_correct += correct\n",
    "            total_num += imgs.size(0)\n",
    "    acc = total_correct/total_num\n",
    "    print(\"Test Acc:\",acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92069bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Over Training...\n",
      "[*]Save Model...\n",
      "ResNet18(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (a1): ReLU()\n",
      "  (r1): ResnetBlock(\n",
      "    (c1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r2): ResnetBlock(\n",
      "    (c1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r3): ResnetBlock(\n",
      "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (down_c1): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (down_b1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r4): ResnetBlock(\n",
      "    (c1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r5): ResnetBlock(\n",
      "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (down_c1): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (down_b1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r6): ResnetBlock(\n",
      "    (c1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r7): ResnetBlock(\n",
      "    (c1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (down_c1): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (down_b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (r8): ResnetBlock(\n",
      "    (c1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a1): ReLU()\n",
      "    (c2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (b2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (a2): ReLU()\n",
      "  )\n",
      "  (p1): AdaptiveAvgPool2d(output_size=1)\n",
      "  (f1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (l1): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"[*]Over Training...\")\n",
    "torch.save(model,save_path)\n",
    "inputs = torch.randn(1,3,32,32).to(device)\n",
    "torch.onnx.export(model,inputs,\"save.onnx\",export_params=True)\n",
    "print(\"[*]Save Model...\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e31ef5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB\n",
      "tensor([[[[0.9961, 0.9961, 1.0000,  ..., 0.9922, 0.9843, 0.9725],\n",
      "          [0.9961, 0.9922, 0.9882,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.9725, 0.9725, 0.9765,  ..., 0.9961, 0.9922, 0.9922],\n",
      "          ...,\n",
      "          [0.0941, 0.1020, 0.1255,  ..., 0.1020, 0.1255, 0.1373],\n",
      "          [0.0941, 0.1098, 0.1176,  ..., 0.1137, 0.1294, 0.1490],\n",
      "          [0.1137, 0.1098, 0.1176,  ..., 0.1216, 0.1137, 0.1333]],\n",
      "\n",
      "         [[0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9882],\n",
      "          [0.9922, 0.9882, 0.9804,  ..., 0.9961, 1.0000, 0.9961],\n",
      "          [0.9490, 0.9490, 0.9569,  ..., 0.9843, 0.9765, 0.9804],\n",
      "          ...,\n",
      "          [0.2078, 0.2235, 0.2392,  ..., 0.1294, 0.1529, 0.1686],\n",
      "          [0.2039, 0.2275, 0.2275,  ..., 0.1529, 0.1647, 0.1843],\n",
      "          [0.2275, 0.2235, 0.2314,  ..., 0.1647, 0.1490, 0.1647]],\n",
      "\n",
      "         [[0.9922, 0.9922, 0.9882,  ..., 0.9961, 0.9961, 0.9961],\n",
      "          [0.9686, 0.9490, 0.9490,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.9020, 0.9020, 0.9059,  ..., 0.9765, 0.9686, 0.9647],\n",
      "          ...,\n",
      "          [0.2549, 0.2667, 0.2863,  ..., 0.1922, 0.2118, 0.2353],\n",
      "          [0.2510, 0.2706, 0.2745,  ..., 0.2196, 0.2314, 0.2549],\n",
      "          [0.2745, 0.2706, 0.2784,  ..., 0.2353, 0.2157, 0.2314]]]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"./3.jpg\")\n",
    "print(img.mode)\n",
    "img = trans(img)\n",
    "torch.no_grad()\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device)\n",
    "pred = model(img)\n",
    "out = pred.argmax(dim = 1)\n",
    "print(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440060d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
